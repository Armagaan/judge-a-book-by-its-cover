{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competetive submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f353b7b7a70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"]='/home/burouj/work/cache'\n",
    "from time import time\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, path_x, path_y) -> None:\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(path_x).drop([\"Id\"], axis=1)\n",
    "        self.labels = pd.read_csv(path_y).drop([\"Id\"], axis=1)\n",
    "        return\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[str, str, int]:\n",
    "        text = self.df[\"Title\"].iloc[index]\n",
    "        image = self.df[\"Cover_image_name\"].iloc[index]\n",
    "        label = self.labels[\"Genre\"].iloc[index]\n",
    "        return (text, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_label = lambda x: int(x)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "pipeline_text = lambda x: tokenizer(x, return_tensors=\"pt\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    list_label = list()\n",
    "    text = list(map(lambda x:x[0], batch))\n",
    "    tokenized=pipeline_text(text)\n",
    "    for (__, __, label) in batch:\n",
    "        list_label.append(pipeline_label(label))\n",
    "    list_label = torch.tensor(list_label, dtype=torch.long)\n",
    "    return tokenized['input_ids'].to(device), tokenized['attention_mask'].to(device), list_label.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book_genre(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Text\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        # NN\n",
    "        self.fc1 = nn.Linear(768, 128)\n",
    "        self.fc2 = nn.Linear(128, 30)\n",
    "        return\n",
    "\n",
    "    def forward(self, text_input_ids, text_attention):\n",
    "        x = self.bert(input_ids=text_input_ids, attention_mask=text_attention)\n",
    "        x = x.last_hidden_state[:, 0, :] # extract the cls embedding.and\n",
    "        x = self.fc1(x).tanh()\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    acc, count = 0, 0\n",
    "    list_predictions = list()\n",
    "    with torch.no_grad():\n",
    "        #todo: images\n",
    "        for texts_input_ids, texts_attention, labels in dataloader:\n",
    "            predictions = model(texts_input_ids, texts_attention)\n",
    "            acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            count += labels.size(0)\n",
    "            list_predictions.append(predictions.argmax(1))\n",
    "    return acc/count, torch.cat(list_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, dataloader_val, optimizer, criterion, max_epochs:int =10):\n",
    "    count = 0\n",
    "    log_interval = 100\n",
    "    PATIENCE = 10\n",
    "    patience = 0\n",
    "    train_acc = 0\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        for index, (texts_input_ids, texts_attention, labels) in enumerate(dataloader_train):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts_input_ids, texts_attention)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            train_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            count += labels.size(0)\n",
    "            if index % log_interval == 0:\n",
    "                val_acc, __ = evaluate(model, dataloader_val)\n",
    "                print(\n",
    "                    f\"Epoch: {epoch}/{max_epochs:2d}\"\n",
    "                    f\" | Batch: {index:4d}/{len(dataloader_train)}\"\n",
    "                    f\" | Train Acc: {100 * train_acc / count:4.5f} %\"\n",
    "                    f\" | Val Acc: {100 * val_acc:4.5f} %\"\n",
    "                )\n",
    "                if val_acc >= best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    patience = 0\n",
    "                    best_model = deepcopy(model)\n",
    "                else:\n",
    "                    patience += 1\n",
    "                if patience == PATIENCE:\n",
    "                    print(\"[STOP] Patience expired.\")\n",
    "                    return best_model\n",
    "        print(\"#\" * 75)\n",
    "    print(\"[STOP] Maximum epochs reached.\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model = Book_genre().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "dataset_train = MultimodalDataset(\n",
    "    path_x=\"../data/train_x.csv\",\n",
    "    path_y=\"../data/train_y.csv\"\n",
    ")\n",
    "val_split_idx = int(0.95 * len(dataset_train))\n",
    "split_train_, split_val_ = random_split(dataset_train, [val_split_idx, len(dataset_train) - val_split_idx])\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=split_train_,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset=split_val_,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train(\n",
    "    model=model,\n",
    "    dataloader_train=dataloader_train,\n",
    "    dataloader_val=dataloader_val,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    max_epochs=EPOCHS\n",
    ")\n",
    "torch.save(best_model, f\"../output/bert_{int(time())}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 50.1579 %\n"
     ]
    }
   ],
   "source": [
    "dataset_test = MultimodalDataset(\n",
    "    path_x=\"../data/non_comp_test_x.csv\",\n",
    "    path_y=\"../data/non_comp_test_y.csv\"\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "acc_test, predictions_test = evaluate(model=model, dataloader=dataloader_test)\n",
    "print(f\"\\nTest accuracy: {100 * acc_test:.4f} %\")\n",
    "\n",
    "# Save output to disk.\n",
    "df = pd.DataFrame({\"Id\": torch.Tensor(range(predictions_test.size(0))), \"Genre\": predictions_test.to(\"cpu\")})\n",
    "df.to_csv(\"non_comp_test_pred_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('perk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c1402249058c2a259b77eb63ffd78b8a656b8670a0121fa21c95a10c93c611b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
