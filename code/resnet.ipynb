{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre classification using ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet152\n",
    "\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, path_x, path_y, img_dir) -> None:\n",
    "        super().__init__()\n",
    "        self.img_dir = img_dir\n",
    "        self.df = pd.read_csv(path_x).drop([\"Id\"], axis=1)\n",
    "        self.labels = pd.read_csv(path_y).drop([\"Id\"], axis=1)\n",
    "        return\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[str, str, int]:\n",
    "        text = self.df[\"Title\"].iloc[index]\n",
    "        image = Image.open(f\"{self.img_dir}/{self.df['Cover_image_name'].iloc[index]}\")\n",
    "        label = self.labels[\"Genre\"].iloc[index]\n",
    "        return (text, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_label = lambda x: int(x)\n",
    "def pipeline_image(image):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    list_image, list_label = list(), list()\n",
    "    for (__, image, label) in batch:\n",
    "        list_image.append(pipeline_image(image))\n",
    "        list_label.append(pipeline_label(label))\n",
    "    list_image = torch.stack(list_image)\n",
    "    list_label = torch.tensor(list_label, dtype=torch.long)\n",
    "    return list_image.to(device), list_label.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book_genre(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Image\n",
    "        self.resnet = resnet152(weights=\"ResNet152_Weights.IMAGENET1K_V1\")\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # NN\n",
    "        self.fc1 = nn.Linear(2048, 128)\n",
    "        self.fc2 = nn.Linear(128, 30)\n",
    "        return\n",
    "\n",
    "    def forward(self, images):\n",
    "        x = self.resnet(images)\n",
    "        x = x.squeeze()\n",
    "        x = self.fc1(x).relu()\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    acc, count = 0, 0\n",
    "    list_predictions = list()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            predictions = model(images)\n",
    "            acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            count += labels.size(0)\n",
    "            list_predictions.append(predictions.argmax(1))\n",
    "    return acc/count, torch.cat(list_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, dataloader_val, optimizer, criterion, max_epochs:int =10):\n",
    "    count = 0\n",
    "    log_interval = 100\n",
    "    PATIENCE = 10\n",
    "    patience = 0\n",
    "    train_acc = 0\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        for index, (images, labels) in enumerate(dataloader_train):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(images)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            train_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            count += labels.size(0)\n",
    "            if index % log_interval == 0:\n",
    "                val_acc, __ = evaluate(model, dataloader_val)\n",
    "                print(\n",
    "                    f\"Epoch: {epoch}/{max_epochs:2d}\"\n",
    "                    f\" | Batch: {index:4d}/{len(dataloader_train)}\"\n",
    "                    f\" | Train Acc: {100 * train_acc / count:4.5f} %\"\n",
    "                    f\" | Val Acc: {100 * val_acc:4.5f} %\"\n",
    "                )\n",
    "                if val_acc >= best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    patience = 0\n",
    "                    best_model = deepcopy(model)\n",
    "                else:\n",
    "                    patience += 1\n",
    "                if patience == PATIENCE:\n",
    "                    print(\"[STOP] Patience expired.\")\n",
    "                    return best_model\n",
    "        print(\"#\" * 75)\n",
    "    print(\"[STOP] Maximum epochs reached.\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model = Book_genre().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "dataset_train = MultimodalDataset(\n",
    "    path_x=f\"{DIR_TRAIN}/train_x.csv\",\n",
    "    path_y=f\"{DIR_TRAIN}/train_y.csv\",\n",
    "    img_dir=f\"{DIR_TRAIN}/images/\"\n",
    ")\n",
    "val_split_idx = int(0.95 * len(dataset_train))\n",
    "split_train_, split_val_ = random_split(dataset_train, [val_split_idx, len(dataset_train) - val_split_idx])\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=split_train_,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset=split_val_,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train(\n",
    "    model=model,\n",
    "    dataloader_train=dataloader_train,\n",
    "    dataloader_val=dataloader_val,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    max_epochs=EPOCHS\n",
    ")\n",
    "torch.save(best_model, f\"resnet_{int(time())}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = MultimodalDataset(\n",
    "    path_x=f\"{DIR_TRAIN}/non_comp_test_x.csv\",\n",
    "    path_y=f\"{DIR_TRAIN}/data/non_comp_test_y.csv\",\n",
    "    img_dir=f\"{DIR_TRAIN}/images\"\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "acc_test, predictions_test = evaluate(model=model, dataloader=dataloader_test)\n",
    "print(f\"\\nTest accuracy: {100 * acc_test:.4f} %\")\n",
    "\n",
    "# Save output to disk.\n",
    "df = pd.DataFrame({\n",
    "    \"Id\": torch.Tensor(range(predictions_test.size(0))),\n",
    "    \"Genre\": predictions_test.to(\"cpu\")\n",
    "})\n",
    "df.to_csv(\"resnet_non_comp_test_pred_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('perk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c1402249058c2a259b77eb63ffd78b8a656b8670a0121fa21c95a10c93c611b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
